{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6228bc1c",
   "metadata": {
    "id": "xSkgt1zf-raF",
    "outputId": "59f4a52f-5eb4-41e5-9fba-07432989fe78",
    "papermill": {
     "duration": 5.620104,
     "end_time": "2025-05-21T16:23:24.361690",
     "exception": false,
     "start_time": "2025-05-21T16:23:18.741586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install torch_geometric torch gdown matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c86aceda",
   "metadata": {
    "id": "5oR2D2Us-xSQ",
    "outputId": "7086cadf-a7fe-4d75-f271-6339bee8164d",
    "papermill": {
     "duration": 4.049235,
     "end_time": "2025-05-21T16:23:28.415556",
     "exception": false,
     "start_time": "2025-05-21T16:23:24.366321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'hackaton'...\n",
      "remote: Enumerating objects: 81, done.\u001b[K\n",
      "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
      "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
      "remote: Total 81 (delta 7), reused 0 (delta 0), pack-reused 62 (from 2)\u001b[K\n",
      "Receiving objects: 100% (81/81), 105.83 MiB | 38.35 MiB/s, done.\n",
      "Resolving deltas: 100% (8/8), done.\n",
      "Updating files: 100% (38/38), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone --branch baselineCe https://github.com/Graph-Classification-Noisy-Label/hackaton.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c129091c",
   "metadata": {
    "id": "tEhfPly6-7UK",
    "outputId": "3078ee06-6312-4fca-f5f9-888fa628c80a",
    "papermill": {
     "duration": 0.013251,
     "end_time": "2025-05-21T16:23:28.434119",
     "exception": false,
     "start_time": "2025-05-21T16:23:28.420868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/onyxia/work/DL-Hackathon/hackaton\n"
     ]
    }
   ],
   "source": [
    "%cd hackaton/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d48103c0",
   "metadata": {
    "id": "PxBvwB0_6xI8",
    "outputId": "5933387c-2cfb-474f-d842-f36a3e2d2a73",
    "papermill": {
     "duration": 83.957666,
     "end_time": "2025-05-21T16:24:52.396720",
     "exception": false,
     "start_time": "2025-05-21T16:23:28.439054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n",
      "Retrieving folder 1wcUVBNQkZ04zStXkglXSgERfIvjSHJiL A\n",
      "Processing file 1C8sjkO6JS0j2SyVwQ07m8PhQ-pHpuI78 test.json.gz\n",
      "Processing file 12N11n8gufNA_C1ns-1IeBseBHgrSfRI1 train.json.gz\n",
      "Retrieving folder 1Tj5YoYYDDXjDxxi-cywZgoDkT0b1Qbz- B\n",
      "Processing file 11GBlrXMdP3HSD60w-56Tu6rbGkR-Ifww test.json.gz\n",
      "Processing file 13vp-Kwef3UgAwMG-dokGwKyARym9iqtL train.json.gz\n",
      "Retrieving folder 1e3B_tBMd693Iwv8x3zRR9c47l5yt_5ey C\n",
      "Processing file 18XVe65ZsQ0PDLCqQa4WmneVhyfjGcXmT test.json.gz\n",
      "Processing file 1z5lvG2CytbLQZt7Jmo9BopzFd0pKejEj train.json.gz\n",
      "Retrieving folder 1cvM0eZwpD4gzjo44_zdodxudVBMrLza1 D\n",
      "Processing file 1Gna_dHnBLX8vKaYGAAqAbw5QPerrNK1u test.json.gz\n",
      "Processing file 1Pc-6LMML80-AgEoLVs2Q5hLtmR_rTEek train.json.gz\n",
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1C8sjkO6JS0j2SyVwQ07m8PhQ-pHpuI78\n",
      "From (redirected): https://drive.google.com/uc?id=1C8sjkO6JS0j2SyVwQ07m8PhQ-pHpuI78&confirm=t&uuid=82de1d41-adc8-4b45-889b-72420ad6690b\n",
      "To: /home/onyxia/work/DL-Hackathon/hackaton/datasets/A/test.json.gz\n",
      "100%|███████████████████████████████████████| 92.4M/92.4M [00:00<00:00, 105MB/s]\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=12N11n8gufNA_C1ns-1IeBseBHgrSfRI1\n",
      "From (redirected): https://drive.google.com/uc?id=12N11n8gufNA_C1ns-1IeBseBHgrSfRI1&confirm=t&uuid=ba1a33f2-2124-4aef-bb4e-21621b35e1e0\n",
      "To: /home/onyxia/work/DL-Hackathon/hackaton/datasets/A/train.json.gz\n",
      "100%|████████████████████████████████████████| 465M/465M [00:06<00:00, 66.8MB/s]\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=11GBlrXMdP3HSD60w-56Tu6rbGkR-Ifww\n",
      "From (redirected): https://drive.google.com/uc?id=11GBlrXMdP3HSD60w-56Tu6rbGkR-Ifww&confirm=t&uuid=fa61d848-c5e7-4ba0-bb6b-a90accdcf6e9\n",
      "To: /home/onyxia/work/DL-Hackathon/hackaton/datasets/B/test.json.gz\n",
      "100%|███████████████████████████████████████| 63.0M/63.0M [00:00<00:00, 109MB/s]\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=13vp-Kwef3UgAwMG-dokGwKyARym9iqtL\n",
      "From (redirected): https://drive.google.com/uc?id=13vp-Kwef3UgAwMG-dokGwKyARym9iqtL&confirm=t&uuid=7d951e77-bc71-4e81-88d8-522b9e320fd1\n",
      "To: /home/onyxia/work/DL-Hackathon/hackaton/datasets/B/train.json.gz\n",
      "100%|████████████████████████████████████████| 223M/223M [00:02<00:00, 94.1MB/s]\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=18XVe65ZsQ0PDLCqQa4WmneVhyfjGcXmT\n",
      "From (redirected): https://drive.google.com/uc?id=18XVe65ZsQ0PDLCqQa4WmneVhyfjGcXmT&confirm=t&uuid=eef16468-d119-4814-8875-5211667151d1\n",
      "To: /home/onyxia/work/DL-Hackathon/hackaton/datasets/C/test.json.gz\n",
      "100%|███████████████████████████████████████| 60.5M/60.5M [00:00<00:00, 103MB/s]\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1z5lvG2CytbLQZt7Jmo9BopzFd0pKejEj\n",
      "From (redirected): https://drive.google.com/uc?id=1z5lvG2CytbLQZt7Jmo9BopzFd0pKejEj&confirm=t&uuid=1c818fc9-7730-4303-b668-003a4d159725\n",
      "To: /home/onyxia/work/DL-Hackathon/hackaton/datasets/C/train.json.gz\n",
      "100%|█████████████████████████████████████████| 308M/308M [00:02<00:00, 108MB/s]\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Gna_dHnBLX8vKaYGAAqAbw5QPerrNK1u\n",
      "From (redirected): https://drive.google.com/uc?id=1Gna_dHnBLX8vKaYGAAqAbw5QPerrNK1u&confirm=t&uuid=e9773478-c455-4786-a220-8e40894fed7c\n",
      "To: /home/onyxia/work/DL-Hackathon/hackaton/datasets/D/test.json.gz\n",
      "100%|███████████████████████████████████████| 94.0M/94.0M [00:00<00:00, 112MB/s]\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Pc-6LMML80-AgEoLVs2Q5hLtmR_rTEek\n",
      "From (redirected): https://drive.google.com/uc?id=1Pc-6LMML80-AgEoLVs2Q5hLtmR_rTEek&confirm=t&uuid=0383af05-1a9b-461d-8a9e-c0c821ff59bf\n",
      "To: /home/onyxia/work/DL-Hackathon/hackaton/datasets/D/train.json.gz\n",
      "100%|█████████████████████████████████████████| 439M/439M [00:03<00:00, 110MB/s]\n",
      "Download completed\n"
     ]
    }
   ],
   "source": [
    "!gdown --folder https://drive.google.com/drive/folders/1Z-1JkPJ6q4C6jX4brvq1VRbJH5RPUCAk -O datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80dab1bc",
   "metadata": {
    "id": "1rockhiQ7Nny",
    "outputId": "2cd2e6f4-5f8f-4a62-f0ec-53e6fc78c9b7",
    "papermill": {
     "duration": 0.138969,
     "end_time": "2025-05-21T16:24:52.549260",
     "exception": false,
     "start_time": "2025-05-21T16:24:52.410291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 16K\n",
      "drwxr-sr-x 2 onyxia users 4.0K May 25 10:09 A\n",
      "drwxr-sr-x 2 onyxia users 4.0K May 25 10:09 B\n",
      "drwxr-sr-x 2 onyxia users 4.0K May 25 10:09 C\n",
      "drwxr-sr-x 2 onyxia users 4.0K May 25 10:09 D\n"
     ]
    }
   ],
   "source": [
    "!ls -lh datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "817b1078",
   "metadata": {
    "id": "lAQuCuIoBbq5",
    "papermill": {
     "duration": 9.949638,
     "end_time": "2025-05-21T16:25:02.510764",
     "exception": false,
     "start_time": "2025-05-21T16:24:52.561126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "# Load utility functions from cloned repository\n",
    "from src.loadData import GraphDataset\n",
    "from src.utils import set_seed\n",
    "from src.models import GNN\n",
    "import argparse\n",
    "\n",
    "# Set the random seed\n",
    "set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a9c70d7",
   "metadata": {
    "id": "Dyf0I2-t9IcW",
    "papermill": {
     "duration": 0.019268,
     "end_time": "2025-05-21T16:25:02.544583",
     "exception": false,
     "start_time": "2025-05-21T16:25:02.525315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_zeros(data):\n",
    "    data.x = torch.zeros(data.num_nodes, dtype=torch.long)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3622cfa1",
   "metadata": {
    "id": "3jKvoQYI9Zbc",
    "papermill": {
     "duration": 0.019599,
     "end_time": "2025-05-21T16:25:02.577661",
     "exception": false,
     "start_time": "2025-05-21T16:25:02.558062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(data_loader, model, optimizer, criterion, device, save_checkpoints, checkpoint_path, current_epoch):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in tqdm(data_loader, desc=\"Iterating training graphs\", unit=\"batch\"):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += (pred == data.y).sum().item()\n",
    "        total += data.y.size(0)\n",
    "\n",
    "    # Save checkpoints if required\n",
    "    if save_checkpoints:\n",
    "        checkpoint_file = f\"{checkpoint_path}_epoch_{current_epoch + 1}.pth\"\n",
    "        torch.save(model.state_dict(), checkpoint_file)\n",
    "        print(f\"Checkpoint saved at {checkpoint_file}\")\n",
    "\n",
    "    return total_loss / len(data_loader),  correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6139b912",
   "metadata": {
    "id": "8peFiIS19ZpK",
    "papermill": {
     "duration": 0.017908,
     "end_time": "2025-05-21T16:25:02.607848",
     "exception": false,
     "start_time": "2025-05-21T16:25:02.589940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate(data_loader, model, device, calculate_accuracy=False):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    total_loss = 0\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(data_loader, desc=\"Iterating eval graphs\", unit=\"batch\"):\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            \n",
    "            if calculate_accuracy:\n",
    "                correct += (pred == data.y).sum().item()\n",
    "                total += data.y.size(0)\n",
    "                total_loss += criterion(output, data.y).item()\n",
    "            else:\n",
    "                predictions.extend(pred.cpu().numpy())\n",
    "    if calculate_accuracy:\n",
    "        accuracy = correct / total\n",
    "        return  total_loss / len(data_loader),accuracy\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbdbd871",
   "metadata": {
    "id": "WanuZKxy9Zs-",
    "papermill": {
     "duration": 0.016728,
     "end_time": "2025-05-21T16:25:02.635694",
     "exception": false,
     "start_time": "2025-05-21T16:25:02.618966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_predictions(predictions, test_path):\n",
    "    script_dir = os.getcwd() \n",
    "    submission_folder = os.path.join(script_dir, \"submission\")\n",
    "    test_dir_name = os.path.basename(os.path.dirname(test_path))\n",
    "    \n",
    "    os.makedirs(submission_folder, exist_ok=True)\n",
    "    \n",
    "    output_csv_path = os.path.join(submission_folder, f\"testset_{test_dir_name}.csv\")\n",
    "    \n",
    "    test_graph_ids = list(range(len(predictions)))\n",
    "    output_df = pd.DataFrame({\n",
    "        \"id\": test_graph_ids,\n",
    "        \"pred\": predictions\n",
    "    })\n",
    "    \n",
    "    output_df.to_csv(output_csv_path, index=False)\n",
    "    print(f\"Predictions saved to {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc3d24da",
   "metadata": {
    "id": "uyHIJS5U9ZzB",
    "papermill": {
     "duration": 0.017765,
     "end_time": "2025-05-21T16:25:02.664538",
     "exception": false,
     "start_time": "2025-05-21T16:25:02.646773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_training_progress(train_losses, train_accuracies, output_dir):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, label=\"Training Loss\", color='blue')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss per Epoch')\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_accuracies, label=\"Training Accuracy\", color='green')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training Accuracy per Epoch')\n",
    "\n",
    "    # Save plots in the current directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"training_progress.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22574fa5",
   "metadata": {
    "papermill": {
     "duration": 0.016577,
     "end_time": "2025-05-21T16:25:02.692205",
     "exception": false,
     "start_time": "2025-05-21T16:25:02.675628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_user_input(prompt, default=None, required=False, type_cast=str):\n",
    "\n",
    "    while True:\n",
    "        user_input = input(f\"{prompt} [{default}]: \")\n",
    "        \n",
    "        if user_input == \"\" and required:\n",
    "            print(\"This field is required. Please enter a value.\")\n",
    "            continue\n",
    "        \n",
    "        if user_input == \"\" and default is not None:\n",
    "            return default\n",
    "        \n",
    "        if user_input == \"\" and not required:\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            return type_cast(user_input)\n",
    "        except ValueError:\n",
    "            print(f\"Invalid input. Please enter a valid {type_cast.__name__}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "139e88b2",
   "metadata": {
    "papermill": {
     "duration": 0.017703,
     "end_time": "2025-05-21T16:25:02.721184",
     "exception": false,
     "start_time": "2025-05-21T16:25:02.703481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_arguments():\n",
    "    args = {}\n",
    "    args['train_path'] = get_user_input(\"Path to the training dataset (optional)\")\n",
    "    args['test_path'] = get_user_input(\"Path to the test dataset\", required=True)\n",
    "    args['num_checkpoints'] = get_user_input(\"Number of checkpoints to save during training\", type_cast=int)\n",
    "    args['device'] = get_user_input(\"Which GPU to use if any\", default=1, type_cast=int)\n",
    "    args['gnn'] = get_user_input(\"GNN type (gin, gin-virtual, gcn, gcn-virtual)\", default='gin')\n",
    "    args['res'] = get_user_input(\"Residuals in GNN ? (1 yes, 0 no)\", default=0)\n",
    "    args['drop_ratio'] = get_user_input(\"Dropout ratio\", default=0.0, type_cast=float)\n",
    "    args['num_layer'] = get_user_input(\"Number of GNN message passing layers\", default=5, type_cast=int)\n",
    "    args['emb_dim'] = get_user_input(\"Dimensionality of hidden units in GNNs\", default=300, type_cast=int)\n",
    "    args['batch_size'] = get_user_input(\"Input batch size for training\", default=32, type_cast=int)\n",
    "    args['epochs'] = get_user_input(\"Number of epochs to train\", default=10, type_cast=int)\n",
    "    args['baseline_mode'] = get_user_input(\"Baseline mode: 1 (CE), 2 (Noisy CE)\", default=1, type_cast=int)\n",
    "    args['noise_prob'] = get_user_input(\"Noise probability p (used if baseline_mode=2)\", default=0.2, type_cast=float)\n",
    "    args['pooling'] = get_user_input(\"type of pooling (sum, mean, max, attention, set2set)\", default='mean')\n",
    "    \n",
    "    return argparse.Namespace(**args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45bffa19",
   "metadata": {
    "papermill": {
     "duration": 0.118164,
     "end_time": "2025-05-21T16:25:02.850799",
     "exception": true,
     "start_time": "2025-05-21T16:25:02.732635",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Path to the training dataset (optional) [None]:  datasets/A/train.json.gz\n",
      "Path to the test dataset [None]:  datasets/A/test.json.gz\n",
      "Number of checkpoints to save during training [None]:  1\n",
      "Which GPU to use if any [1]:  \n",
      "GNN type (gin, gin-virtual, gcn, gcn-virtual) [gin]:  gcn\n",
      "Residuals in GNN ? (1 yes, 0 no) [0]:  1\n",
      "Dropout ratio [0.0]:  0.2\n",
      "Number of GNN message passing layers [5]:  \n",
      "Dimensionality of hidden units in GNNs [300]:  \n",
      "Input batch size for training [32]:  \n",
      "Number of epochs to train [10]:  1\n",
      "Baseline mode: 1 (CE), 2 (Noisy CE) [1]:  \n",
      "Noise probability p (used if baseline_mode=2) [0.2]:  \n",
      "type of pooling (sum, mean, max, attention, set2set) [mean]:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments received:\n",
      "train_path: datasets/A/train.json.gz\n",
      "test_path: datasets/A/test.json.gz\n",
      "num_checkpoints: 1\n",
      "device: 1\n",
      "gnn: gcn\n",
      "res: 1\n",
      "drop_ratio: 0.2\n",
      "num_layer: 5\n",
      "emb_dim: 300\n",
      "batch_size: 32\n",
      "epochs: 1\n",
      "baseline_mode: 1\n",
      "noise_prob: 0.2\n",
      "pooling: mean\n"
     ]
    }
   ],
   "source": [
    "def populate_args(args):\n",
    "    print(\"Arguments received:\")\n",
    "    for key, value in vars(args).items():\n",
    "        print(f\"{key}: {value}\")\n",
    "args = get_arguments()\n",
    "populate_args(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09b57d62",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NoisyCrossEntropyLoss(torch.nn.Module):\n",
    "    def __init__(self, p_noisy):\n",
    "        super().__init__()\n",
    "        self.p = p_noisy\n",
    "        self.ce = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        losses = self.ce(logits, targets)\n",
    "        weights = (1 - self.p) + self.p * (1 - torch.nn.functional.one_hot(targets, num_classes=logits.size(1)).float().sum(dim=1))\n",
    "        return (losses * weights).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f58745df",
   "metadata": {
    "id": "lHX55XGECXBr",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "script_dir = os.getcwd() \n",
    "# device = torch.device(f\"cuda:{args.device}\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_checkpoints = args.num_checkpoints if args.num_checkpoints else 3\n",
    "    \n",
    "if args.gnn == 'gin':\n",
    "    model1 = GNN(gnn_type='gin', num_class=6, num_layer=args.num_layer, emb_dim=args.emb_dim, drop_ratio=args.drop_ratio, virtual_node=False, residual = True if args.res == 1 else False, graph_pooling=args.pooling).to(device)\n",
    "    model2 = GNN(gnn_type='gin', num_class=6, num_layer=args.num_layer, emb_dim=args.emb_dim, drop_ratio=args.drop_ratio, virtual_node=False, residual = True if args.res == 1 else False, graph_pooling=args.pooling).to(device)\n",
    "elif args.gnn == 'gin-virtual':\n",
    "    model1 = GNN(gnn_type='gin', num_class=6, num_layer=args.num_layer, emb_dim=args.emb_dim, drop_ratio=args.drop_ratio, virtual_node=True, residual = True if args.res == 1 else False, graph_pooling=args.pooling).to(device)\n",
    "    model2 = GNN(gnn_type='gin', num_class=6, num_layer=args.num_layer, emb_dim=args.emb_dim, drop_ratio=args.drop_ratio, virtual_node=True, residual = True if args.res == 1 else False, graph_pooling=args.pooling).to(device)\n",
    "elif args.gnn == 'gcn':\n",
    "    model1 = GNN(gnn_type='gcn', num_class=6, num_layer=args.num_layer, emb_dim=args.emb_dim, drop_ratio=args.drop_ratio, virtual_node=False, residual = True if args.res == 1 else False, graph_pooling=args.pooling).to(device)\n",
    "    model2 = GNN(gnn_type='gcn', num_class=6, num_layer=args.num_layer, emb_dim=args.emb_dim, drop_ratio=args.drop_ratio, virtual_node=False, residual = True if args.res == 1 else False, graph_pooling=args.pooling).to(device)\n",
    "elif args.gnn == 'gcn-virtual':\n",
    "    model1 = GNN(gnn_type='gcn', num_class=6, num_layer=args.num_layer, emb_dim=args.emb_dim, drop_ratio=args.drop_ratio, virtual_node=True, residual = True if args.res == 1 else False, graph_pooling=args.pooling).to(device)\n",
    "    model2 = GNN(gnn_type='gcn', num_class=6, num_layer=args.num_layer, emb_dim=args.emb_dim, drop_ratio=args.drop_ratio, virtual_node=True, residual = True if args.res == 1 else False, graph_pooling=args.pooling).to(device)\n",
    "else:\n",
    "    raise ValueError('Invalid GNN type')\n",
    "    \n",
    "optimizer1 = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "if args.baseline_mode == 2:\n",
    "    criterion = NoisyCrossEntropyLoss(args.noise_prob)\n",
    "else:\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a025914",
   "metadata": {
    "id": "BTYT5jYuChPb",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dir_name = os.path.basename(os.path.dirname(args.test_path))\n",
    "logs_folder = os.path.join(script_dir, \"logs\", test_dir_name)\n",
    "log_file = os.path.join(logs_folder, \"training.log\")\n",
    "os.makedirs(os.path.dirname(log_file), exist_ok=True)\n",
    "logging.basicConfig(filename=log_file, level=logging.INFO, format='%(asctime)s - %(message)s')\n",
    "logging.getLogger().addHandler(logging.StreamHandler())\n",
    "\n",
    "checkpoint_path = os.path.join(script_dir, \"checkpoints\", f\"model_{test_dir_name}_best.pth\")\n",
    "checkpoints_folder = os.path.join(script_dir, \"checkpoints\", test_dir_name)\n",
    "os.makedirs(checkpoints_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbca6779",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(checkpoint_path) and not args.train_path:\n",
    "    model1.load_state_dict(torch.load(checkpoint_path))\n",
    "    print(f\"Loaded best model from {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74027780-797a-46f2-80f2-0925e6cb8728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_coteaching(train_loader, model1, model2, optimizer1, optimizer2, criterion, device, forget_rate, epoch, num_epochs):\n",
    "    model1.train()\n",
    "    model2.train()\n",
    "\n",
    "    total_correct1 = total_correct2 = total_samples = 0\n",
    "    running_loss1 = 0.0\n",
    "    running_loss2 = 0.0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device, non_blocking=True)\n",
    "\n",
    "        out1 = model1(batch)\n",
    "        out2 = model2(batch)\n",
    "\n",
    "        # Perte par échantillon (shape: [batch_size])\n",
    "        loss1 = criterion(out1, batch.y)\n",
    "        loss2 = criterion(out2, batch.y)\n",
    "\n",
    "        remember_rate = 1.0 - forget_rate\n",
    "        num_remember = int(remember_rate * batch.y.size(0))\n",
    "\n",
    "        _, idx1 = loss1.topk(num_remember, largest=False)\n",
    "        _, idx2 = loss2.topk(num_remember, largest=False)\n",
    "\n",
    "        loss1_update = criterion(out1[idx2], batch.y[idx2]).mean()\n",
    "        loss2_update = criterion(out2[idx1], batch.y[idx1]).mean()\n",
    "\n",
    "        optimizer1.zero_grad()\n",
    "        loss1_update.backward()\n",
    "        optimizer1.step()\n",
    "\n",
    "        optimizer2.zero_grad()\n",
    "        loss2_update.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "        # On calcule la loss moyenne pondérée par la taille du batch (pour l’epoch)\n",
    "        running_loss1 += loss1_update.item() * batch.y.size(0)\n",
    "        running_loss2 += loss2_update.item() * batch.y.size(0)\n",
    "\n",
    "        # Calcul des bonnes prédictions\n",
    "        total_correct1 += (out1.argmax(dim=1) == batch.y).sum().item()\n",
    "        total_correct2 += (out2.argmax(dim=1) == batch.y).sum().item()\n",
    "        total_samples += batch.y.size(0)\n",
    "\n",
    "    avg_loss1 = running_loss1 / total_samples\n",
    "    avg_loss2 = running_loss2 / total_samples\n",
    "    acc1 = total_correct1 / total_samples\n",
    "    acc2 = total_correct2 / total_samples\n",
    "\n",
    "    return acc1, acc2, avg_loss1, avg_loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef4a359c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating eval graphs: 100%|██████████| 71/71 [00:16<00:00,  4.26batch/s]\n",
      "Iterating eval graphs: 100%|██████████| 71/71 [00:16<00:00,  4.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1 | Forget rate: 0.000\n",
      "Train Loss Model1: 1.5496, Acc: 0.4190\n",
      "Train Loss Model2: 1.5490, Acc: 0.4184\n",
      "Val   Loss Model1: 2.1767, Acc: 0.2815\n",
      "Val   Loss Model2: 1.6069, Acc: 0.3918\n",
      "[Co-Teaching] Best model1 updated and saved at /home/onyxia/work/DL-Hackathon/hackaton/checkpoints/A/model_A\n"
     ]
    }
   ],
   "source": [
    "if args.train_path:\n",
    "    full_dataset = GraphDataset(args.train_path, transform=add_zeros)\n",
    "    val_size = int(0.2 * len(full_dataset))\n",
    "    train_size = len(full_dataset) - val_size\n",
    "\n",
    "    generator = torch.Generator().manual_seed(12)\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size], generator=generator)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=args.batch_size, shuffle=False)\n",
    "\n",
    "    num_epochs = args.epochs\n",
    "    best_val_accuracy = 0.0\n",
    "\n",
    "    train_losses_model1 = []\n",
    "    train_losses_model2 = []\n",
    "    train_accuracies1 = []\n",
    "    train_accuracies2 = []\n",
    "    val_losses_model1 = []\n",
    "    val_losses_model2 = []\n",
    "    val_accuracies1 = []\n",
    "    val_accuracies2 = []\n",
    "\n",
    "\n",
    "    if num_checkpoints > 1:\n",
    "        checkpoint_intervals = [int((i + 1) * num_epochs / num_checkpoints) for i in range(num_checkpoints)]\n",
    "    else:\n",
    "        checkpoint_intervals = [num_epochs]\n",
    "\n",
    "    def get_forget_rate(epoch, total_epochs, max_forget=0.2):\n",
    "        return min(max_forget, max_forget * epoch / (total_epochs * 0.5))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        forget_rate = get_forget_rate(epoch, num_epochs)\n",
    "\n",
    "        # Phase d'entraînement\n",
    "        train_acc1, train_acc2, train_loss1, train_loss2 = train_coteaching(\n",
    "            train_loader, model1, model2, optimizer1, optimizer2,\n",
    "            criterion, device, forget_rate, epoch, num_epochs\n",
    "        )\n",
    "\n",
    "        # Phase de validation\n",
    "        val_loss1, val_acc1 = evaluate(val_loader, model1, device, calculate_accuracy=True)\n",
    "        val_loss2, val_acc2 = evaluate(val_loader, model2, device, calculate_accuracy=True)\n",
    "\n",
    "        # Stocker les métriques\n",
    "        train_losses_model1.append(train_loss1)\n",
    "        train_losses_model2.append(train_loss2)\n",
    "        train_accuracies1.append(train_acc1)\n",
    "        train_accuracies2.append(train_acc2)\n",
    "    \n",
    "        val_losses_model1.append(val_loss1)\n",
    "        val_losses_model2.append(val_loss2)\n",
    "        val_accuracies1.append(val_acc1)\n",
    "        val_accuracies2.append(val_acc2)\n",
    "    \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Forget rate: {forget_rate:.3f}\")\n",
    "        print(f\"Train Loss Model1: {train_loss1:.4f}, Acc: {train_acc1:.4f}\")\n",
    "        print(f\"Train Loss Model2: {train_loss2:.4f}, Acc: {train_acc2:.4f}\")\n",
    "        print(f\"Val   Loss Model1: {val_loss1:.4f}, Acc: {val_acc1:.4f}\")\n",
    "        print(f\"Val   Loss Model2: {val_loss2:.4f}, Acc: {val_acc2:.4f}\")\n",
    "        \n",
    "        if val_acc1 > best_val_accuracy:\n",
    "            best_val_accuracy = val_acc1\n",
    "            torch.save(model1.state_dict(), os.path.join(checkpoints_folder, f\"model_{test_dir_name}\"))\n",
    "            print(f\"[Co-Teaching] Best model1 updated and saved at {checkpoints_folder}/model_{test_dir_name}\")\n",
    "\n",
    "    # Assuming you have train_losses1 and train_losses2 collected similarly to train_accuracies\n",
    "    plot_training_progress(train_losses_model1, train_accuracies1, os.path.join(logs_folder, \"plots_model1\"))\n",
    "    plot_training_progress(val_losses_model1, val_accuracies1, os.path.join(logs_folder, \"plotsVal_model1\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07594aff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11241"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del train_dataset\n",
    "del train_loader\n",
    "del full_dataset\n",
    "del val_dataset\n",
    "del val_loader\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba668fff",
   "metadata": {
    "id": "xsXZIj4Mdu3I",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = GraphDataset(args.test_path, transform=add_zeros)\n",
    "test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7828e983",
   "metadata": {
    "id": "x1OnGq_nCmTr",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on CUDA device 1 but torch.cuda.device_count() is 1. Please use torch.load with map_location to map your storages to an existing device.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model1.load_state_dict(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      2\u001b[39m predictions = evaluate(test_loader, model1, device, calculate_accuracy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      3\u001b[39m save_predictions(predictions, args.test_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/serialization.py:1516\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1514\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[32m   1515\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1516\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1517\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1518\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1519\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_weights_only_unpickler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1520\u001b[39m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1521\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1523\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1524\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/serialization.py:2114\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   2112\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[32m   2113\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m2114\u001b[39m result = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2115\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2117\u001b[39m torch._utils._validate_loaded_sparse_tensors()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/_weights_only_unpickler.py:532\u001b[39m, in \u001b[36mUnpickler.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    525\u001b[39m         \u001b[38;5;28mtype\u001b[39m(pid) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m\n\u001b[32m    526\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pid) > \u001b[32m0\u001b[39m\n\u001b[32m    527\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m torch.serialization._maybe_decode_ascii(pid[\u001b[32m0\u001b[39m]) != \u001b[33m\"\u001b[39m\u001b[33mstorage\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    528\u001b[39m     ):\n\u001b[32m    529\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m UnpicklingError(\n\u001b[32m    530\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOnly persistent_load of storage is allowed, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpid[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    531\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m532\u001b[39m     \u001b[38;5;28mself\u001b[39m.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpersistent_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpid\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key[\u001b[32m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [BINGET[\u001b[32m0\u001b[39m], LONG_BINGET[\u001b[32m0\u001b[39m]]:\n\u001b[32m    534\u001b[39m     idx = (read(\u001b[32m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m key[\u001b[32m0\u001b[39m] == BINGET[\u001b[32m0\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m unpack(\u001b[33m\"\u001b[39m\u001b[33m<I\u001b[39m\u001b[33m\"\u001b[39m, read(\u001b[32m4\u001b[39m)))[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/serialization.py:2078\u001b[39m, in \u001b[36m_load.<locals>.persistent_load\u001b[39m\u001b[34m(saved_id)\u001b[39m\n\u001b[32m   2076\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2077\u001b[39m     nbytes = numel * torch._utils._element_size(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m2078\u001b[39m     typed_storage = \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2079\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2080\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2082\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/serialization.py:2044\u001b[39m, in \u001b[36m_load.<locals>.load_tensor\u001b[39m\u001b[34m(dtype, numel, key, location)\u001b[39m\n\u001b[32m   2040\u001b[39m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[32m   2041\u001b[39m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[32m   2043\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch._guards.detect_fake_mode(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2044\u001b[39m     wrap_storage = \u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2045\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2046\u001b[39m     storage._fake_device = location\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/serialization.py:698\u001b[39m, in \u001b[36mdefault_restore_location\u001b[39m\u001b[34m(storage, location)\u001b[39m\n\u001b[32m    678\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    679\u001b[39m \u001b[33;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[32m    680\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    695\u001b[39m \u001b[33;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[32m    696\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    699\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    700\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/serialization.py:636\u001b[39m, in \u001b[36m_deserialize\u001b[39m\u001b[34m(backend_name, obj, location)\u001b[39m\n\u001b[32m    634\u001b[39m     backend_name = torch._C._get_privateuse1_backend_name()\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m location.startswith(backend_name):\n\u001b[32m--> \u001b[39m\u001b[32m636\u001b[39m     device = \u001b[43m_validate_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackend_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    637\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj.to(device=device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.12/site-packages/torch/serialization.py:615\u001b[39m, in \u001b[36m_validate_device\u001b[39m\u001b[34m(location, backend_name)\u001b[39m\n\u001b[32m    613\u001b[39m     device_count = device_module.device_count()\n\u001b[32m    614\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m device_index >= device_count:\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    616\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAttempting to deserialize object on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m device \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    617\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m but torch.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbackend_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.device_count() is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    618\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPlease use torch.load with map_location to map your storages \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    619\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mto an existing device.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    620\u001b[39m         )\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m device\n",
      "\u001b[31mRuntimeError\u001b[39m: Attempting to deserialize object on CUDA device 1 but torch.cuda.device_count() is 1. Please use torch.load with map_location to map your storages to an existing device."
     ]
    }
   ],
   "source": [
    "model1.load_state_dict(torch.load(checkpoint_path))\n",
    "predictions = evaluate(test_loader, model1, device, calculate_accuracy=False)\n",
    "save_predictions(predictions, args.test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343c36b2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 108.457758,
   "end_time": "2025-05-21T16:25:04.482169",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-21T16:23:16.024411",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
